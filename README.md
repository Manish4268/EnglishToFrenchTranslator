# ğŸ“˜ Translation Evaluation

Evaluation of different strategies on LLM translation

---

## ğŸ§  Project Summary

This research investigates the effectiveness of two advanced techniquesâ€”**Retrieval-Augmented Generation (RAG)** and **Chain of Thought (CoT)**â€”in enhancing Large Language Model (LLM) translation capabilities. The focus is on conversational French-to-English translation, especially on informal and culturally rich dialogues. This study evaluates both individual and combined effects of RAG and CoT.

---

## ğŸ“ Architecture

![Architecture](./assets/RAG_Arch.drawio.png)

---

## ğŸ” RAG and CoT Difference

![RAG and CoT](./assets/difference.png)

---

## ğŸ“ˆ Improvement Observed

![RAG and CoT Difference](./assets/Figure_1.png)

---

## ğŸ“‹ Methodology Overview

- **Baseline Evaluation** using standard LLM translation
- **Data Selection**: 10,000 sentence pairs with informal expressions, slang, idioms
- **Technique Implementation**:
  - RAG: Uses external document retrieval to provide context-aware translation
  - CoT: Uses step-by-step reasoning to capture nuanced meanings
- **Evaluation Metrics**: BLEU scores and human evaluation for adequacy, fluency, and cultural accuracy

---

## ğŸ§ª Models Evaluated

- `facebook/nllb-200-distilled-1.3B`
- `ChatGPT`
- `ChatGPT-o1-preview`

---

## ğŸ“ Key Findings

- **RAG** improved BLEU scores significantly across all tested models
- **CoT** led to more human-like translations with better preservation of humor and context
- Combined usage of RAG and CoT produced the most effective results for conversational accuracy

---

## ğŸ“š References

A full list of academic references and resources is provided in the accompanying [report](./report.pdf).

---

## ğŸ‘¨â€ğŸ’» Contributors

- **Ajaykumar Premkumar Nair** â€” B00968276  
  âœ‰ï¸ ajay.nair@dal.ca

- **Manish Shankar Jadhav** â€” B00969328  
  âœ‰ï¸ mn649712@dal.ca
